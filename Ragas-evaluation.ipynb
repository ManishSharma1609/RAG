{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langsmith ragas numpy openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-runtime-cu12 (/workspaces/RAG/.venv/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-runtime-cu12 (/workspaces/RAG/.venv/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cuda-runtime-cu12 (/workspaces/RAG/.venv/lib/python3.12/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(name='BaseCamp Q&A', description='Taken from: https://basecamp.com/handbook', data_type=<DataType.kv: 'kv'>, id=UUID('6f330976-9a78-4fd3-9718-5ebba585af98'), created_at=datetime.datetime(2025, 3, 28, 19, 29, 35, 17929, tzinfo=datetime.timezone.utc), modified_at=datetime.datetime(2025, 3, 28, 19, 29, 35, 17929, tzinfo=datetime.timezone.utc), example_count=0, session_count=0, last_session_start_time=None, inputs_schema=None, outputs_schema=None, transformations=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client()\n",
    "dataset_url = (\n",
    "    \"https://smith.langchain.com/public/56fe54cd-b7d7-4d3b-aaa0-88d7a2d30931/d\"\n",
    ")\n",
    "dataset_name = \"BaseCamp Q&A\"\n",
    "client.clone_public_dataset(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "url = \"https://storage.googleapis.com/benchmarks-artifacts/basecamp-data/basecamp-data.zip\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "with io.BytesIO(response.content) as zipped_file:\n",
    "    with zipfile.ZipFile(zipped_file, \"r\") as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "docs = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".md\"):\n",
    "        with open(os.path.join(data_dir, filename), \"r\") as file:\n",
    "            docs.append({\"file\": filename, \"content\": file.read()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "\n",
    "\n",
    "class VectorStoreRetriever:\n",
    "    def __init__(self, docs: list, vectors: list, oai_client):\n",
    "        self._arr = np.array(vectors)\n",
    "        self._docs = docs\n",
    "        self._client = oai_client\n",
    "\n",
    "    @classmethod\n",
    "    async def from_docs(cls, docs, oai_client):\n",
    "        embeddings = await oai_client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[doc[\"content\"] for doc in docs]\n",
    "        )\n",
    "        vectors = [emb.embedding for emb in embeddings.data]\n",
    "        return cls(docs, vectors, oai_client)\n",
    "\n",
    "    @traceable\n",
    "    async def query(self, query: str, k: int = 5) -> List[dict]:\n",
    "        embed = await self._client.embeddings.create(\n",
    "            model=\"text-embedding-3-small\", input=[query]\n",
    "        )\n",
    "\n",
    "        scores = np.array(embed.data[0].embedding) @ self._arr.T\n",
    "        top_k_idx = np.argpartition(scores, -k)[-k:]\n",
    "        top_k_idx_sorted = top_k_idx[np.argsort(-scores[top_k_idx])]\n",
    "        return [\n",
    "            {**self._docs[idx], \"similarity\": scores[idx]} for idx in top_k_idx_sorted\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "\n",
    "class NaiveRagBot:\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o-mini\"):\n",
    "        self._retriever = retriever\n",
    "\n",
    "        self._client = wrap_openai(openai.AsyncClient())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable\n",
    "    async def get_answer(self, question: str):\n",
    "        similar = await self._retriever.query(question)\n",
    "        response = await self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful AI assistant.\"\n",
    "                    \" Use the following docs to help answer the user's question.\\n\\n\"\n",
    "                    f\"## Docs\\n\\n{similar}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in similar],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = await VectorStoreRetriever.from_docs(docs, openai.AsyncClient())\n",
    "rag_bot = NaiveRagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At 37signals, employees are entitled to 18 days of paid time off (PTO) each year, in addition to 11 local holidays. This vacation time is prorated bas'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await rag_bot.get_answer(\"How much time off do we get?\")\n",
    "response[\"answer\"][:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/RAG/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.smith import RunEvalConfig\n",
    "from ragas.integrations.langchain import EvaluatorChain\n",
    "from ragas.metrics import (\n",
    "    answer_correctness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall,\n",
    "    faithfulness,\n",
    ")\n",
    "\n",
    "\n",
    "evaluators = [\n",
    "    EvaluatorChain(metric)\n",
    "    for metric in [\n",
    "        answer_correctness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "        faithfulness,\n",
    "    ]\n",
    "]\n",
    "eval_config = RunEvalConfig(custom_evaluators=evaluators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'pertinent-passenger-58' at:\n",
      "https://smith.langchain.com/o/163bb599-804b-58d8-a6e7-07b73cf89382/datasets/6f330976-9a78-4fd3-9718-5ebba585af98/compare?selectedSessions=3aee663d-5c39-4475-bcff-e49d831105e4\n",
      "\n",
      "View all tests for Dataset BaseCamp Q&A at:\n",
      "https://smith.langchain.com/o/163bb599-804b-58d8-a6e7-07b73cf89382/datasets/6f330976-9a78-4fd3-9718-5ebba585af98\n",
      "[-------------------------------------------->     ] 19/21"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error evaluating run 878f8b72-bc1f-4585-bc94-aea43c90e422 with EvaluatorChain: APIConnectionError('Connection error.')\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1500, in _request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_async/http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/anyio/streams/tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/anyio/streams/tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"/usr/local/python/current/lib/python3.12/asyncio/locks.py\", line 209, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/current/lib/python3.12/asyncio/mixins.py\", line 20, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x7f5850c33620 [unset]> is bound to a different event loop\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain_core/tracers/evaluation.py\", line 129, in _evaluate_in_project\n",
      "    evaluation_result = evaluator.evaluate_run(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/integrations/langchain.py\", line 198, in evaluate_run\n",
      "    eval_output = self.invoke(chain_eval, include_run_info=True)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain/chains/base.py\", line 170, in invoke\n",
      "    raise e\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain/chains/base.py\", line 160, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/integrations/langchain.py\", line 93, in _call\n",
      "    score = self.metric.single_turn_score(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/metrics/base.py\", line 497, in single_turn_score\n",
      "    raise e\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/metrics/base.py\", line 491, in single_turn_score\n",
      "    score = loop.run_until_complete(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/nest_asyncio.py\", line 98, in run_until_complete\n",
      "    return f.result()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/usr/local/python/current/lib/python3.12/asyncio/futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/usr/local/python/current/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 220, in _single_turn_ascore\n",
      "    score = await self._ascore(row, callbacks)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 230, in _ascore\n",
      "    statements_x = await self._create_simplified_statements(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py\", line 208, in _create_simplified_statements\n",
      "    statements = await self.statement_generator_prompt.generate(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
      "    output_single = await self.generate_multiple(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
      "    resp = await llm.generate(\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 109, in generate\n",
      "    result = await agenerate_text_with_retry(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/current/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/python/current/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/ragas/llms/base.py\", line 254, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 853, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 813, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"/usr/local/python/current/lib/python3.12/asyncio/tasks.py\", line 314, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 981, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1157, in _agenerate\n",
      "    response = await self.async_client.create(**payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 2000, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1524, in _request\n",
      "    return await self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/RAG/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1534, in _request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error in EvaluatorCallbackHandler.on_chain_end callback: APIConnectionError('Connection error.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[------------------------------------------------->] 21/21"
     ]
    }
   ],
   "source": [
    "results = await client.arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=rag_bot.get_answer,\n",
    "    evaluation=eval_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
